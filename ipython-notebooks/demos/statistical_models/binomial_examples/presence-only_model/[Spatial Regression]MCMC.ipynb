{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model template using multiple polygons\n",
    "This is an exercise to test the computing time for fitting and predicting spatial models using an assortment of different polygons.\n",
    "\n",
    "This can work as a general template for other models and data pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "initialise"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('/apps')\n",
    "import django\n",
    "django.setup()\n",
    "from drivers.tree_builder import TreeNeo\n",
    "from drivers.graph_models import TreeNode, Order, Family, graph,Kingdom,Occurrence\n",
    "from drivers.graph_models import Cell,Mex4km, countObjectsOf\n",
    "from drivers.graph_models import pickNode\n",
    "import traversals.strategies as st\n",
    "from os import walk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "\n",
    "## Use the ggplot style\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(path_to_dataset):\n",
    "    _files = []\n",
    "    for (dirpath, dirnames,filenames) in walk(path_to_dataset):\n",
    "        _files = map(lambda f : dirpath + '/' + f ,filenames)\n",
    "    #print(_files)\n",
    "    ## Read all data\n",
    "    dataset = map(lambda f : pd.read_csv(f,na_values=[\"N.A.\",\"NaN\",\"N.A\"],encoding='utf8'),_files)  \n",
    "    dataset = map(lambda d : st.toGeoDataFrame(d,xcoord_name='Longitude',ycoord_name='Latitude'),dataset)    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursera_path = '/outputs/presence_only_models/data/burseras'\n",
    "bursera_dataset = loadDataset(bursera_path)\n",
    "\n",
    "train_path = '/outputs/presence_only_models/data/root'\n",
    "train_dataset = loadDataset(train_path)\n",
    "## Predictors\n",
    "pred_path = '/outputs/presence_only_models/predictors/datasetp1'\n",
    "pred_dataset = loadDataset(pred_path)\n",
    "### PATCH, the thing is taking backwards the order of the lists of files, because of the name\n",
    "pred_dataset.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recreating the polygons\n",
    "from django.contrib.gis.geos import Point, Polygon\n",
    "xcoord = -99.76\n",
    "ycoord = 17.55\n",
    "p = Point(xcoord,ycoord,srid=4326)\n",
    "radii = np.linspace(0.08,1, 10)\n",
    "polys = map(lambda r : p.buffer(r),radii)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the predictors\n",
    "In this case we will bring all the variables to start working with everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raster_api.tools import RasterData\n",
    "from raster_api.models import raster_models_dic as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing of CSV files\n",
    "def preparePredictors(pred_dataset):\n",
    "    \"\"\"\n",
    "    Prepares the predictor datasets.\n",
    "    Parameters : \n",
    "        pred_dataset : A list of dataframes obtained from the predictor function \n",
    "        i.e. compileDataCube (for the moment hold in notebook, obtaining_predictors)\n",
    "    Returns :\n",
    "        list of geopandas dataframes.\n",
    "    \n",
    "    \"\"\"\n",
    "    datapred = pred_dataset\n",
    "    datapred = datapred.replace(\"N.A\",np.nan)\n",
    "    ## Remove NAs from coordinates (necessary, given the hereogeneous datasource (included in worldpop and elevation)\n",
    "    datapred.dropna(subset=['Longitude','Latitude'],inplace=True)\n",
    "    ## Remove problematic string columns, so that all of them can be numeric\n",
    "    #datapred = datapred.drop(['vegname','inegiv5name'],axis=1)\n",
    "    ## Convert to numeric\n",
    "    ## Very nice way to convert to numeric \n",
    "    #cols = datapred.columns.drop('Unnamed: 0')\n",
    "    #datapred[cols] = datapred[cols].apply(pd.to_numeric,errors='coerce')\n",
    "    ## New data set without nas for any other column\n",
    "    datacube_clean = datapred.dropna()\n",
    "    ## Convert to geopandas\n",
    "    #datacube_clean = st.toGeoDataFrame(datacube_clean,xcoord_name='Longitude',ycoord_name='Latitude')\n",
    "    return {'clean' : datacube_clean, 'full' :datapred}\n",
    "    #return datacube_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dataset_dic= map(lambda p : preparePredictors(p),pred_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map(lambda p : p['full'].plot(column='DistanceToRoadMex'),prediction_dataset_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to numeric\n",
    "## Very nice way to convert to numeric \n",
    "#cols = datapred.columns.drop('Unnamed: 0')\n",
    "#datapred[cols] = datapred[cols].apply(pd.to_numeric,errors='coerce')\n",
    "## New data set without nas for any other column\n",
    "#datacube_clean = datapred.dropna()\n",
    "## Convert to geopandas\n",
    "#from external_plugins.spystats.spystats import tools as tl\n",
    "#datacube_clean = tl.toGeoDataFrame(datacube_clean,xcoord_name='Longitude',ycoord_name='Latitude')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, lets start the ,modelling here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## just a small subsample\n",
    "#datafull = datatrain.replace('N.A.',np.nan).astype('float')\n",
    "#datafull = datasets[9].dropna()\n",
    "#Y = datafull.Burseraceae\n",
    "i = 1\n",
    "datatrain = train_dataset[i]\n",
    "Y = datatrain.Burseraceae\n",
    "datapred = prediction_dataset_dic[i]\n",
    "polygon = polys[i]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pymc3.variational.callbacks import CheckParametersConvergence\n",
    "with pm.Model() as model:\n",
    "\n",
    "    tau = pm.HalfNormal('tau',sd=10)\n",
    " \n",
    "    sigma = pm.HalfNormal('sigma',sd=10)\n",
    "\n",
    "    phi = pm.Uniform('phi',0,15)\n",
    "    Tau = pm.gp.cov.Constant(tau)\n",
    "    cov = (sigma * pm.gp.cov.Matern32(2,phi,active_dims=[0,1])) + Tau\n",
    "\n",
    "    ## Parameters for linear predictor\n",
    "    b0 = pm.Normal('b0',mu=0,sd=10)\n",
    "    b = pm.Normal('b',mu=0,sd=10,shape=2)\n",
    "    mf = pm.gp.mean.Linear(coeffs=[b],intercept=b0) \n",
    "    ## The latent function\n",
    "    gp = pm.gp.Latent(cov_func=cov)\n",
    "    \n",
    "\n",
    "    f = gp.prior(\"latent_field\", X=datatrain[['Longitude','Latitude','Elevation_mean','MaxTemperature_mean']].values,reparameterize=False)\n",
    "  \n",
    "    y_obs = pm.Bernoulli('y_obs',logit_p=f,observed=Y.values)\n",
    "\n",
    "    ## Variational\n",
    "    \n",
    "    %time mean_field = pm.fit(method='advi', callbacks=[CheckParametersConvergence()],n=15000)    \n",
    "    %time trace = mean_field.sample(draws=5000)\n",
    "\n",
    "    %time f_star = gp.conditional(\"f_star\", datapred['clean'][['Longitude','Latitude','Elevation','MeanTemperature']].values)\n",
    "    ## Full data\n",
    "\n",
    "    pred_samples = pm.sample_ppc(trace, vars=[f_star], samples=100)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pm.traceplot(trace)\n",
    "from raster_api.tools import RasterContainer\n",
    "from raster_api.models import ETOPO1,MeanTemperature\n",
    "from raster_api.tools import RasterData\n",
    "from sketches.models import Country\n",
    "from mesh.models import MexMesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/biospytial/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "## This is for calculating the signal\n",
    "from pymc3.variational.callbacks import CheckParametersConvergence\n",
    "def FitMyModel(Y,train,predictor):\n",
    "    #\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        ## [R | Y]\n",
    "\n",
    "        tau = pm.HalfNormal('tau',sd=10)\n",
    "        sigma = pm.HalfNormal('sigma',sd=10)\n",
    "        phi = pm.Uniform('phi',0,15)\n",
    "\n",
    "        Tau = pm.gp.cov.Constant(tau)\n",
    "        cov = (sigma * pm.gp.cov.Matern32(2,phi,active_dims=[0,1])) + Tau\n",
    "\n",
    "        ## Parameters for linear predictor\n",
    "        #b0 = pm.Normal('b0',mu=0,sd=10)\n",
    "        b = pm.Normal('b',mu=0,sd=10,shape=3)\n",
    "        mf = pm.gp.mean.Linear(coeffs=[b]) \n",
    "\n",
    "        ## The latent function\n",
    "        gp = pm.gp.Latent(cov_func=cov)\n",
    "        f = gp.prior(\"latent_field\", X=train[['Longitude','Latitude','DistanceToRoadMex_mean','WorldPopLatam2010_mean','vegid']].values,reparameterize=False)\n",
    "\n",
    "\n",
    "        ## Other model M2\n",
    "\n",
    "        beta_y = pm.Normal(\"betay\",mu=0, sd=10,shape=2)\n",
    "\n",
    "        theta = beta_y[0] + beta_y[1] * train.MaxTemperature_mean.values\n",
    "\n",
    "        yy = pm.Bernoulli(\"yy\",logit_p=theta,observed=Y.values)\n",
    "\n",
    "\n",
    "        #y_obs = pm.Bernoulli('y_obs',logit_p=(f*yy),observed=Y.values)\n",
    "\n",
    "\n",
    "        #trace = pm.fit(method='advi', callbacks=[CheckParametersConvergence()],n=15000)    \n",
    "        trace = pm.sample(300)\n",
    "        #trace = trace.sample(draws=5000)\n",
    "\n",
    "\n",
    "        f_star = gp.conditional(\"f_star\", predictor['clean'][['Longitude','Latitude','DistanceToRoadMex','WorldPopLatam2010','vegid']].values)\n",
    "\n",
    "        pred_samples = pm.sample_ppc(trace, vars=[f_star], samples=100)\n",
    "        return pred_samples\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotThings(pred_samples):\n",
    "    preds = pd.DataFrame(pred_samples['f_star']).transpose()\n",
    "    import scipy.special as sp\n",
    "    alpha = sp.logit(0.5)\n",
    "    mean_sample = preds.mean(axis=1)\n",
    "    q_025 = preds.quantile(0.025,axis=1)\n",
    "    q_975 = preds.quantile(0.975,axis=1)\n",
    "    prob_gt05 = preds.apply(lambda row : float(sum(row > alpha))/100,axis=1)\n",
    "    surface_data = pd.DataFrame({'mean_sample' : mean_sample, 'q_025':q_025,'q_975':q_975,'prob_gt05':prob_gt05})\n",
    "\n",
    "    #preds['idx'] = data_star.index.values\n",
    "    surface_data['idx'] = datapred['clean'].index.values\n",
    "    predictions = datapred['full'].merge(surface_data,how='left',left_index=True,right_on='idx',suffixes=('_obs','_pred'))\n",
    "    predicted_data = predictions.mean_sample.values\n",
    "    # Raster Container\n",
    "    ql_presences_of_something = RasterContainer(predictions.q_025.values,use_metadata_from=elevation.rasterdata,exponential_fam=\"Bernoulli\")\n",
    "    ql_presences_of_something.display_field(band=2,origin='Lower',cmap=plt.cm.RdBu,interpolation='None',title=\"Quantiles 0.025\")\n",
    "\n",
    "    mean_presences_of_something = RasterContainer(predicted_data,use_metadata_from=elevation.rasterdata,exponential_fam=\"Bernoulli\")\n",
    "    mean_presences_of_something.display_field(band=2,origin='Lower',cmap=plt.cm.RdBu,interpolation='None',title=\"mean probability\")\n",
    "\n",
    "    qh_presences_of_something = RasterContainer(predictions.q_975.values,use_metadata_from=elevation.rasterdata,exponential_fam=\"Bernoulli\")\n",
    "    qh_presences_of_something.display_field(band=2,origin='Lower',cmap=plt.cm.RdBu,interpolation='None',title=\"quantile 0.097\")\n",
    "\n",
    "    ## Probability of the probaaility of presences bigger than 0.5\n",
    "    prob5 = RasterContainer(predictions.prob_gt05.values,use_metadata_from=elevation.rasterdata,exponential_fam=\"Bernoulli\")\n",
    "    prob5.display_field(band=2,origin='Lower',cmap=plt.cm.RdBu,interpolation='None',title=\"probability of exceding more than 0.5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    #datatrain = bursera_dataset[i]\n",
    "    datatrain = train_dataset[i]\n",
    "    #Y = datatrain.Burseraceae\n",
    "    Y = datatrain.Burseraceae\n",
    "    datapred = prediction_dataset_dic[i]\n",
    "    polygon = polys[i]\n",
    "    polygon_predict = polygon\n",
    "    elevation = RasterData(rastermodelinstance=ETOPO1,border=polygon)\n",
    "    pixel_size = 0.01\n",
    "    elevation.rescale(pixel_size)\n",
    "    #elevation.display_field(origin='Lower',interpolation='None')\n",
    "    %time pred_samples = FitMyModel(Y,datatrain,datapred)\n",
    "    plotThings(pred_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "fig, ax = plt.subplots(figsize=(10, 9));\n",
    "\n",
    "#ncounts_families.display_field(band=2,origin='Lower',title='family richness')\n",
    "expit(ql_presences_of_something.rasterdata.bands[0].data())\n",
    "plt.imshow(ql_presences_of_something.rasterdata.bands[1].data(),origin='Lower',cmap=plt.cm.Greens)\n",
    "plt.title(\"Presences quantile 0.025\")\n",
    "plt.colorbar(orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "fig, ax = plt.subplots(figsize=(10, 9));\n",
    "\n",
    "#ncounts_families.display_field(band=2,origin='Lower',title='family richness')\n",
    "plt.imshow(mean_presences_of_something.rasterdata.bands[1].data(),origin='Lower',cmap=plt.cm.Greens,clim=(0,1))\n",
    "\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.title('Probability of presences (mean surface)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "fig, ax = plt.subplots(figsize=(10, 9));\n",
    "\n",
    "#ncounts_families.display_field(band=2,origin='Lower',title='family richness')\n",
    "plt.imshow(qh_presences_of_something.rasterdata.bands[1].data(),origin='Lower',cmap=plt.cm.Greens,clim=(0,1))\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.title(\"Presences quantile 0.975\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 9));\n",
    "\n",
    "#ncounts_families.display_field(band=2,origin='Lower',title='family richness')\n",
    "plt.imshow(prob5.rasterdata.bands[1].data(),origin='Lower',cmap=plt.cm.RdBu,clim=(0,1))\n",
    "plt.colorbar(orientation='horizontal')\n",
    "plt.title(\"Probability of probability more than 0.5 of presence of Burseracea family\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results to GEotif!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"sample_root\"\n",
    "ql_presences_of_something.exportToGeoTiff(\"ql_\"+name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_presences_of_something.exportToGeoTiff(\"mean_\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qh_presences_of_something.exportToGeoTiff(\"qh_\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob5.exportToGeoTiff(\"prob05\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
