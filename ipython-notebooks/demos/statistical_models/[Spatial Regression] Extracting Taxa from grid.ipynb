{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Regression of Abundance Data\n",
    "---\n",
    "***\n",
    "Here I show how to extract different taxonomic information at cell level.\n",
    "Although there exists a method for building the taxonomic tree within a single cell, the process can be computationally intensive because it depends on extracting the total amount of occurrences in each cell. From there, it traverses fromtop to bottom the tree looking for the corresponding nodes.\n",
    "\n",
    "The approach is usefull when one needs a small number of trees but it'll become increasingly slow if the amount of cells or occurrences increases. \n",
    "\n",
    "---\n",
    "\n",
    "## Extracting specific taxonomic levels en each cells\n",
    "\n",
    "The method studied here makes use of the relationship type `IS_IN` stored in the knowledge graph.\n",
    "\n",
    "> Note: *There was a problem with the design of the OGM implementation (py2neo.ogm). The retrieval of linked nodes based on a specific relation does not distinguish different labels. In other words it returns the totality of the data that has the  specific relationship given a node.*\n",
    "\n",
    "> Patchy solution: \n",
    "The solution was to include extra methods for the class Cell `has_[taxas]`. This method/attribute returns a graph selector that points to the corresponding nodes.\n",
    "\n",
    "> Stabile Fix \n",
    "Make relationships as specific as possible (given the data). For example, if instead of using the relation type \n",
    "* *IS_IN* for (Bursera:Family) -[IS_IN]-> (Grid:Cell) \n",
    "change it to:\n",
    "* *Family_IS_IN* for (Bursera:Family) -[IS_IN]-> (Grid:Cell)\n",
    "Let's get started.\n",
    "As usual we need to load the necessary modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('/apps')\n",
    "import django\n",
    "django.setup()\n",
    "from drivers.tree_builder import TreeNeo\n",
    "from drivers.graph_models import TreeNode, Order, Family, graph,Kingdom,Occurrence\n",
    "from drivers.graph_models import Cell,Mex4km, countObjectsOf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "\n",
    "## Use the ggplot style\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random selection of cells.\n",
    "\n",
    "*Note* : There was a big problem in the data arquitecture. For storage reasons I couldn't load the complete world bioclimatic layers. Therefore I needed to put a regional subset that comprises only the Mexican Territory. \n",
    "For this reason, it is necessary that any approach for selecting subsamples needs to be constrained (filter) by this geometry. \n",
    "We can do that with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sketches.models import Country\n",
    "from mesh.models import MexMesh\n",
    "\n",
    "Mexico = Country.objects.filter(name__contains=\"exico\").get()\n",
    "mexican_cells = MexMesh.objects.filter(cell__intersects=Mexico.geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all cell ids\n",
    "ids = list(mexican_cells.values('pk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from traversals.sampling import UniformRandomCellSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO Using custom random seed of: 12345\n",
      "INFO:biospytial.graph_models:Using custom random seed of: 12345\n",
      "INFO Compiling Query and asking the Graph Database\n",
      "INFO:biospytial.graph_models:Compiling Query and asking the Graph Database\n"
     ]
    }
   ],
   "source": [
    "CellNodeClass = Mex4km\n",
    "list_of_cell_ids = ids\n",
    "n = len(ids)\n",
    "selection_of_cells = UniformRandomCellSample(ids,Mex4km,sample_size=200,random_seed=12345,with_replacement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selection should be as follow:\n",
    "    * Convert to pandas\n",
    "    * Generate random numbers uniform on that range\n",
    "    * use iloc to get the id values\n",
    "    * Use the normal methodology.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract richness and Environmental covariates from cells at a given taxonomic level\n",
    "Options are: Family, Order, Spicies, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from traversals import strategies as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time data = st.getEnvironmentAndRichnessFromListOfCells(list_of_cells=selection_of_cells,taxonomic_level_name='Family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes time because it need to calculate on the fly the summary statistic of each cell. It is using the postgis backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st.getEnvironmentAndRichnessFromListOfCells?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.plot(column='n_Family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from external_plugins.spystats.spystats import tools as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vg = tl.Variogram(data,response_variable_name='n_Family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vg.plot(with_envelope=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's bring some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1 = tl.ExponentialVariogram(nugget=3.5,range_a=15,sill=6.5)\n",
    "m2 = tl.GaussianVariogram(nugget=3.5,range_a=15,sill=6.5)\n",
    "m4 = tl.SphericalVariogram(nugget=3.5,range_a=15,sill=6.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vg.fitVariogramModel(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,30,100)\n",
    "\n",
    "vg.plot(with_envelope=False,n_bins=100)\n",
    "plt.plot(x,vg.model.f(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## We will retrieve environmental data from another region using the 'raster_api'\n",
    "##We will do it like this:\n",
    "cell = selection_of_cells.first()\n",
    "## Go up 5 scales\n",
    "upcell = cell.upperCell.next().upperCell.next().upperCell.next().upperCell.next().upperCell.next()\n",
    "## Get the raster for this area, example Elevation\n",
    "elev = upcell.getAssociatedRasterAreaData('Elevation')\n",
    "## Get a dataframe\n",
    "data_s = elev.toPandasDataFrame()\n",
    "## Convert it to geoDataFrame\n",
    "data_s = tl.toGeoDataFrame(data_s,xcoord_name='Longitude',ycoord_name='Latitude')\n",
    "## Remove NAs\n",
    "data_star = data_s.dropna()\n",
    "## Restablish index to be continuous, this is important\n",
    "#data_star.reset_index(drop=True,inplace=True)\n",
    "## Plot it\n",
    "data_star.plot(column=0)\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small diversion, use the Mexican polygon to obtain covariates for all the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from raster_api.tools import RasterData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from raster_api.models import ETOPO1\n",
    "elev_map = RasterData(ETOPO1,border=Mexico.geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time elev_map.getRaster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elev_map.display_field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elev_data = elev_map.toPandasDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_data_elev_data = elev_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## a systematic sample because is huge\n",
    "k = 10\n",
    "idxs = range(0,len(w_data_elev_data),k)\n",
    "small_sample = w_data_elev_data.loc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(w_data_elev_data.Latitude,w_data_elev_data.Longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "data.columns = [u'n_Family', u'Longitude', u'Latitude', u'Elevation_mean',\n",
    "       u'MaxTemperature_mean', u'MeanTemperature_mean', u'MinTemperature_mean',\n",
    "       u'Precipitation_mean', u'SolarRadiation_mean', u'Vapor_mean',\n",
    "       u'WindSpeed_mean', u'geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "glmodel = GLM.from_formula('n_Family ~ Elevation_mean',data=data)\n",
    "res = glmodel.fit()\n",
    "print(res.summary())\n",
    "\n",
    "\n",
    "z = np.array([0.0,0.0])\n",
    "coefs = np.append(z,res.params.values[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## cero coef for long lat\n",
    "z = np.array([0.0,0.0])\n",
    "coefs = np.append(z,res.params.values[1:])\n",
    "print(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Analysis, GP only one parameter to fit\n",
    "# The variational method is much beter.\n",
    "from pymc3.variational.callbacks import CheckParametersConvergence\n",
    "\n",
    "with pm.Model() as model:\n",
    "    sigma = 1.0\n",
    "    #range_a=10.13\n",
    "    \n",
    "    \n",
    "    tau = pm.Uniform('tau',0,5.0)\n",
    "    #sigma = pm.Flat('sigma')\n",
    "    #phi = pm.HalfNormal('phi',mu=8,sd=3)\n",
    "    #phi = pm.Uniform('phi',6,12)\n",
    "    phi = pm.Uniform('phi',0,15)\n",
    "    \n",
    "    Tau = pm.gp.cov.Constant(tau)\n",
    "    \n",
    "    cov = sigma * pm.gp.cov.Matern32(2,phi,active_dims=[0,1]) + Tau\n",
    "    #K = cov(grid[['Lon','Lat']].values)\n",
    "    #phiprint = tt.printing.Print('phi')(phi)\n",
    "    \n",
    "    \n",
    "    mf = pm.gp.mean.Linear(coeffs=coefs,intercept=res.params.values[0])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## The latent function\n",
    "    gp = pm.gp.Latent(cov_func=cov)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## I don't know why this\n",
    "    #f = gp.prior(\"latent_field\", X=data[['Longitude','Latitude']].values,reparameterize=False)\n",
    "    \n",
    "    f = gp.prior(\"latent_field\", X=data[['Longitude','Latitude','Elevation_mean']].values,reparameterize=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #f_print = tt.printing.Print('latent_field')(f)\n",
    "    \n",
    "    y_obs = pm.Poisson('y_obs',mu=np.exp(f),observed=data[['n_Family']].values)\n",
    "    \n",
    "    #y_obs = pm.MvNormal('y_obs',mu=np.zeros(n*n),cov=K,observed=grid.Z)\n",
    "\n",
    "    #gp = pm.gp.Latent(cov_func=cov,observed=sample)\n",
    "    # Use elliptical slice sampling\n",
    "    #ess_step = pm.EllipticalSlice(vars=[f_sample], prior_cov=K)\n",
    "    #step = pm.HamiltonianMC()\n",
    "    #step = pm.Metropolis()\n",
    "    #%time trace = pm.sample(5000,step)#,tune=0,chains=1)\n",
    "    ## Variational\n",
    "    \n",
    "    %time mean_field = pm.fit(method='advi', callbacks=[CheckParametersConvergence()],n=15000)    \n",
    "    %time trace = mean_field.sample(draws=5000)\n",
    "\n",
    "#with model:    \n",
    "    \n",
    "    ## For predicting\n",
    "    %time f_star = gp.conditional(\"f_star\", data_star.iloc[:,:3].values)\n",
    "                    \n",
    "#with model:\n",
    "    ## sampling predictions posterior predictive checks\n",
    "    pred_samples = pm.sample_ppc(trace, vars=[f_star], samples=10)\n",
    "\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(pred_samples['f_star']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds['mean_sample'] = preds.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds['idx'] = data_star.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test1 = data_s.merge(preds,how='left',left_index=True,right_on='idx',suffixes=('_obs','_pred'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 9));\n",
    "plt.scatter(test1.Longitude,test1.Latitude,c=test1.iloc[:,0],s=200)\n",
    "plt.colorbar()\n",
    "#plt.scatter(data.Longitude,data.Latitude,c=data.n_Family,s=20,alpha=0.8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 9));\n",
    "plt.scatter(test1.Longitude,test1.Latitude,c=np.exp(test1.mean_sample.values),s=50,alpha=0.9)\n",
    "plt.colorbar()\n",
    "#plt.scatter(gdata.Longitude,gdata.Latitude,c='k',s=gdata.Nsp,alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to a raster format.\n",
    " ## Motivation\n",
    " It's important for visualization and compatibility with GIS software to generate the results in a standard raster format.\n",
    " For achieving this I'll explore *rasterio* package (MapBox, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rasterio as rast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rasterio.features import rasterize,guard_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shapes = ((geom,val) for geom, val in zip(test1.geometry,np.exp(test1.mean_sample.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shapes = list(shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elev.rasterdata.geotransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elev.rasterdata.bands[0].data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rastband1 = elev.rasterdata.bands[0].data()\n",
    "\n",
    "newr = rasterize(shapes,out_shape=(60,65),all_touched=False,fill=np.nan,transform=elev.rasterdata.geotransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = test1.mean_sample.values.reshape(60,65)\n",
    "Z1 = np.ma.masked_where(Z == np.nan,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.exp(Z1),cmap=plt.cm.Accent)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## With pcolormesh\n",
    "x = np.linspace(0,100,65)\n",
    "y = np.linspace(0,100,60)\n",
    "XX,YY = np.meshgrid(x,y)\n",
    "ZZ = np.exp(Z1)\n",
    "z_min = np.nanmin(ZZ)\n",
    "z_max = np.nanmax(ZZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 9));\n",
    "plt.pcolor(XX,YY,np.exp(Z1),cmap='RdBu', vmin=z_min, vmax=z_max)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = elev.rasterdata.bands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = b.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# colormap normalizer\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9));\n",
    "plt.pcolor(XX,YY,values,cmap=plt.cm.CMRmap_r,norm = colors.Normalize(vmin=0.0,vmax=1800))\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
