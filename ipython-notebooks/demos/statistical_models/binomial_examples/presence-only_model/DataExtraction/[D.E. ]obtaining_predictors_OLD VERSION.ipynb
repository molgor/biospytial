{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the predictors\n",
    "[ OLD VERSION] Please archive it.\n",
    "> This was intended to be a starting point for developing the tools for data extraction.\n",
    "In this case we will bring all the variables to start working with everything.\n",
    "### The fast forward way!\n",
    "It now includes population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('/apps')\n",
    "import django\n",
    "django.setup()\n",
    "from drivers.tree_builder import TreeNeo\n",
    "from drivers.graph_models import TreeNode, Order, Family, graph,Kingdom,Occurrence\n",
    "from drivers.graph_models import Cell,Mex4km, countObjectsOf\n",
    "from drivers.graph_models import pickNode\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "\n",
    "## Use the ggplot style\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raster_api.tools import RasterData\n",
    "from raster_api.models import raster_models_dic as models\n",
    "from sketches.models import Country\n",
    "from mesh.models import MexMesh\n",
    "from ecoregions.models import TerrEcoregions,InegiIV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuilding polygons from obtained pseudio absences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.contrib.gis.geos import Point, Polygon\n",
    "xcoord = -99.76\n",
    "ycoord = 17.55\n",
    "p = Point(xcoord,ycoord,srid=4326)\n",
    "radii = np.linspace(0.08,1, 10)\n",
    "polys = map(lambda r : p.buffer(r),radii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict = { key : RasterData(models[key],border=polys[4],name=key) for key,value in models.iteritems()}\n",
    "## Without resamling (whole data)\n",
    "pixel_size = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Raster object at 0x7f0cd3cd1f40>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wp = datadict['WorldPopLatam2010']\n",
    "prec = datadict['Precipitation']\n",
    "wp.rescale(pixel_size,algorithm='Cubic')\n",
    "prec.rescale(pixel_size,algorithm='Cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_df1 = wp.toPandasDataFrame(aggregate_with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_df1 = prec.toPandasDataFrame(aggregate_with_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_df2 = compileDataCube(pixel_size=pixel_size,polygon_border=polys[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_df2 = compileDataCube(pixel_size=pixel_size,polygon_border=polys[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 21 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def extractVegetation(list_points):\n",
    "    \"\"\"\n",
    "    Given a list of points it will return a dataframe of the corresponding vegetation \n",
    "    type from the TerrEcoregions and INEGI series V.\n",
    "    To be included in data extraction method, but there's no time for it, there's never time for anything!\n",
    "    Returns a dataframe.\n",
    "    \"\"\"\n",
    "    points = list_points\n",
    "    ecoregions = map(lambda p : TerrEcoregions.objects.filter(geom__intersects=p),points)\n",
    "    ecovalues = map(lambda q : q.values_list('wwf_mhtnum','wwf_mhtnam'),ecoregions)\n",
    "    inegiregions = map(lambda p : InegiIV.objects.filter(geom__intersects=p),points)\n",
    "    inegivalues = map(lambda q : q.values_list('covid','name'),inegiregions)\n",
    "    ecovals = [r.get() if r.exists() else (np.nan,'NaN') for r in ecovalues ]\n",
    "    inegivals = [r.get() if r.exists() else (np.nan,'NaN') for r in inegivalues ]\n",
    "    # Compile dataframe\n",
    "    vegdat = pd.DataFrame(ecovals)\n",
    "    inegidat = pd.DataFrame(inegivals)\n",
    "    vegdat.columns = ['vegid','vegname']\n",
    "    inegidat.columns = ['inegiv5id','inegiv5name']\n",
    "    results = pd.concat([vegdat,inegidat],axis=1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileDataCube(pixel_size,polygon_border):\n",
    "    datadict = { key : RasterData(models[key],border=polygon_border) for key,value in models.iteritems()}\n",
    "    datacube_field = map(lambda raster : raster.rescale(pixel_size,algorithm='Cubic'),datadict.itervalues())\n",
    "    datacube = datacube_field\n",
    "    cubes = map(lambda (k,v): np.mean(v.toNumpyArray(),axis=0), datadict.iteritems())\n",
    "    extractCoords = lambda (k,v) : v.getCoordinates() \n",
    "    lcoords = map(extractCoords,datadict.iteritems())\n",
    "    coords = lcoords[0]\n",
    "    ## Oke I need a way to extract the dataframe, maybe aggregate it by mean \n",
    "    dataframe_cube = map(lambda cube: pd.DataFrame(cube.flatten()),cubes)\n",
    "    datacube = pd.concat(dataframe_cube,axis=1)\n",
    "    datacube = pd.concat([datacube,coords],axis=1)\n",
    "    datacube.columns = datadict.keys() + list(coords.columns)\n",
    "    \n",
    "    toPoint = lambda r : Point(tuple(r))\n",
    "    points = coords.apply(toPoint,axis=1)\n",
    "    vegdf = extractVegetation(points)\n",
    "    predictors = pd.concat([datacube,vegdf],axis=1)\n",
    "    return {'raster_dic':datadict, 'pred_df':predictors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do all this for all the polygons\n",
    "predictors_dataframes = map(lambda p : compileDataCube(pixel_size=pixel_size,polygon_border=p),polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = map(lambda p : p['pred_df'],predictors_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let´s save it for the posterity\n",
    "We need to encode the name into utf8, because.... python 2 !! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,d in enumerate(dataframes):\n",
    "    cad = '/outputs/presence_only_models/predictors/pred-%s.csv'%i\n",
    "    print(cad)\n",
    "    d.to_csv(cad,encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
